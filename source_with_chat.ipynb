{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"./keys.env\")\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_key[:5]\n",
    "# os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4')\n",
    "\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema, PydanticOutputParser\n",
    "\n",
    "system_message = SystemMessagePromptTemplate.from_template(\"You are a helpful assistant that, when given a video transcript, identifies the claims made and any sources provided\")\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "{transcript}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "class Claim(BaseModel):\n",
    "    claim: str = Field(description=\"an exact quote from the transcript in which the claim is made\")\n",
    "    source: str = Field(description=\"the source provided for the claim or the word none if none are given\")\n",
    "\n",
    "    # @validator(\"claim\")\n",
    "    # def claim_in_transcript(cls, field):\n",
    "    #     if str(field) not in transcript:\n",
    "    #         raise ValueError(\"No bro :(\")\n",
    "    #     return field\n",
    "\n",
    "class List_Claims(BaseModel):\n",
    "    pairs: List[Claim]\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=List_Claims)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        system_message,\n",
    "        human_message \n",
    "    ],\n",
    "    input_variables=[\"transcript\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "with open('test/truth/scishow_dna/transcript.txt', 'r') as f:\n",
    "  transcript = f.read()[:658]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_prompt = prompt.format(transcript=transcript)\n",
    "# output = llm(final_prompt)\n",
    "_input = prompt.format_prompt(transcript=transcript)\n",
    "output = llm(_input.to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_parser.parse(output.content))\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
